{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import colorsys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = []\n",
    "for h in range(0, 360, 40): # H\n",
    "    for s in range(0, 101, 20): # S\n",
    "        for v in range(0, 101, 20): # V\n",
    "            r, g, b = colorsys.hsv_to_rgb(h / 360, s / 100, v / 100)\n",
    "            colors.append([int(r * 255), int(g * 255), int(b * 255)])\n",
    "palette = np.array(colors)\n",
    "\n",
    "def quantize_to_palette(image):\n",
    "    X_query = image.reshape(-1, 3).astype(np.float32)\n",
    "    X_index = palette.astype(np.float32)\n",
    "\n",
    "    knn = cv2.ml.KNearest_create()\n",
    "    knn.train(X_index, cv2.ml.ROW_SAMPLE, np.arange(len(palette)))\n",
    "    ret, results, neighbours, dist = knn.findNearest(X_query, 1)\n",
    "\n",
    "    quantized_image = np.array([palette[idx] for idx in neighbours.astype(int)])\n",
    "    quantized_image = quantized_image.reshape(image.shape)\n",
    "    return quantized_image\n",
    "\n",
    "\n",
    "def extract_ring_2(path, index):\n",
    "    og_img = cv2.imread(path)\n",
    "    B, G, R = cv2.split(og_img)\n",
    "    B_norm = cv2.normalize(B, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "    G_norm = cv2.normalize(G, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "    R_norm = cv2.normalize(R, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "    normalized_image = cv2.merge([B_norm, G_norm, R_norm])\n",
    "    img = np.uint8(normalized_image)\n",
    "\n",
    "    hsv_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv_image)\n",
    "    s = s.astype(np.float32)\n",
    "    s = s * 1.5\n",
    "    v = v * 1.5\n",
    "    s = np.clip(s, 0, 255).astype(np.uint8)\n",
    "    v = np.clip(v, 0, 255).astype(np.uint8)\n",
    "    hsv_modified = cv2.merge([h, s, v])\n",
    "    img = cv2.cvtColor(hsv_modified, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    dimensions = (360, 640)\n",
    "    scale_factor_x = og_img.shape[1] / dimensions[0]\n",
    "    scale_factor_y = og_img.shape[0] / dimensions[1]\n",
    "    img = cv2.resize(img, (dimensions), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # refine once\n",
    "    lower2 = np.array([50, 0, 100])     # darken\n",
    "    upper2 = np.array([255, 150, 255])\n",
    "    mask2 = cv2.inRange(img, lower2, upper2)\n",
    "    img = cv2.bitwise_and(img, img, mask=mask2)\n",
    "    B, G, R = cv2.split(img)\n",
    "    B_norm = cv2.normalize(B, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "    G_norm = cv2.normalize(G, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "    R_norm = cv2.normalize(R, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "    normalized_image = cv2.merge([B_norm, G_norm, R_norm])\n",
    "    img = np.uint8(normalized_image)\n",
    "    # cv2.imwrite(f'temp.png', img)\n",
    "\n",
    "    # actual thresholding time\n",
    "    lower = np.array([100, 0, 150])     # darken\n",
    "    upper = np.array([255, 200, 255])\n",
    "    mask = cv2.inRange(img, lower, upper)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (4, 4))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    # white_mask = cv2.inRange(img, (180, 180, 180), (255, 255, 255))\n",
    "    # mask = cv2.subtract(mask, white_mask)\n",
    "    segmented = cv2.bitwise_and(img, img, mask=mask)\n",
    "    # cv2.imwrite(f'temp2.png', segmented)\n",
    "\n",
    "    # Find contours\n",
    "    gray = cv2.cvtColor(segmented, cv2.COLOR_BGR2GRAY)\n",
    "    contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    cv2.drawContours(segmented, [largest_contour], -1, (0, 255, 0), 2)\n",
    "\n",
    "    upscaled_contour = largest_contour.copy().astype(np.float32)\n",
    "    upscaled_contour[:, :, 0] *= scale_factor_x\n",
    "    upscaled_contour[:, :, 1] *= scale_factor_y\n",
    "    upscaled_contour = upscaled_contour.astype(np.int32)\n",
    "\n",
    "    # Create a blank mask with the same dimensions as the image\n",
    "    mask_2 = np.zeros_like(og_img)\n",
    "    cv2.drawContours(mask_2, [upscaled_contour], -1, (255, 255, 255), thickness=cv2.FILLED)\n",
    "    white_background = np.full_like(og_img, 255)\n",
    "    masked_image = np.where(mask_2 == 255, og_img, white_background)\n",
    "\n",
    "    cv2.imwrite(f'test1.png', masked_image)\n",
    "\n",
    "extract_ring_2('img_1.jpg', 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
